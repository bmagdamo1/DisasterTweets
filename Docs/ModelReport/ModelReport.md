# Model Report

## Introduction
Phase 2 was set aside as the primary time to train our model. One might recall that in Phase 1, ‚ÄúWe initially created a baseline model that did not involve any real Natural Language Processing and instead used a count vectorizer to represent the Tweets.  This gave us a baseline F1 score of between 0.73 and 0.77 depending on where the data was split.‚Äù In this phase, we switched to a Simple Transformers ClassificationModel with inputs from a pre-trained RoBERTa model called ‚Äúroberta-base‚Äù.  This is the base version of the RoBERTa model that is case sensitive.  This improved our performance up to approximately 0.81 on the testing dataset we set aside and 0.81857 in our first submission to Kaggle.

We believe that we are, for all intents and purposes, finished training the model. The only thing left to do is include the tuned hyperparameters in this model. For Phase 3, we simply have to feed in a new set of data to the existing model in Brendan Magdamo‚Äôs notebook on GitHub. This model will use the hyperparameters decided by the tuning job that is running as this document gets written. Our new data which was collected during Phase 2 will serve as the test dataset that will be used for the final model predictions and the model dashboard. 

## String Sanitization
We began our model training by doing the basics. We removed urls, html, and punctuation from the input tweets. Initially we considered keeping some of the punctuation with the reasoning that the hashtag symbol may have been a useful indicator. However, it was ultimately determined that this negatively impacted model results so all punctuation was removed. We also lowercased the text. We concluded that no meaningful information would be found in the capitalization of different words because randomly collected text data, particularly Twitter data, is not often subject to traditional grammatical conventions. Hence, the pre-trained RoBERTa model may take into account a word capitalization that is not actually grammatically correct and therefore may convey an alternate meaning to the one the Twitter user intended.  Finally, and after much deliberation, we chose to preserve emojis in the text. In PD 3.2, we documented how exploratory data analysis revealed that the relative distributions of common emojis like üòÇ, üò≠, and üî• were different between tweets for real and ‚Äúfalse alarm‚Äù disaster tweets. Therefore, they were deemed to have some predictive power in the model output and so we chose to include them. Initially we thought that we may have needed to create an encoder for this. However, modern language models have built-in emoji parsing capabilities, so there was no need on our part to create some sort of word representation or encoding, as the model could read and understood the UTF encoding for the different emojis.

	
## Abbreviations
Rather than ask the model to learn two ways of expressing the same sentiment (the words and  the abbreviation), we replaced a hand-curated dictionary of common abbreviations with the words themselves. We arrived at the list by searching for commonly used abbreviations online.  We found a Python dictionary that had a plethora of terms that people would be likely to use in an online setting. This dictionary of abbreviations may be less useful for other types of text data, but it worked very well with our Twitter data. The replacement of abbreviations, in conjunction with also removing all non-ASCII characters, increased our F1 score from 0.81857 all the way to 0.83512. This was a significant improvement so we would recommend utilizing the same Python dictionary for similar tasks that involve Twitter text data as it strongly impacted the outcome. 

## Back Translation
Back Translation can be an effective way to reduce overfitting. It‚Äôs similar to how in image-based learning one might grow the size of their database by including flipped, filtered, or otherwise processed versions of the source images. However in the context of textual data, the idea is to translate back and forth between different languages. This is done by translating the input strings from English to some other language and then back into English. The resulting translation will be slightly different than the original, giving us a little bit of extra information that can be useful for creating the model and improving performance.

In our case, we used the Helsinki-NLP module to translate to French and then back again. While our algorithm worked for small batches, it eventually led to a GPU memory error when applied to the full dataset. Alternatively, we used Excel‚Äôs builtin translate functionality to translate train.csv and test.csv, then concatenated the translated files with the originals. Unfortunately, the quality of the translations provided by Excel‚Äôs translate functions were poor and our F1 score in Kaggle decreased from 0.83 to 0.825. If we had more time, we would have found a solution to the Helsinki-NLP model memory problem. We also would have treated the language as a sort of ‚Äúhyperparameter‚Äù and tried it again with (a) other Romance languages similar to English (like Spanish, Italian, etc.) and (b) languages very unlike English (Latin, Chinese, Arabic, etc). Unfortunately, due to time constraints and the decision to spend the majority of Phase 3 working on the creation of the final dashboard to demonstrate the model‚Äôs usefulness, the back translation was discarded.

## Modeling Algorithms
We used Simple Transformers for all of our Phase 2 model training because of its simple interface. It also included an easy way to ensure training with CUDA support (by passing use_cuda=True to the ClassificationArgs constructor). We wanted to try using both RoBERTa and DistilBERT as we spent a fair amount of time researching the BERT model and knew it was state of the art in terms of NLP. Based upon our research and our experiences in the process of working to get a BERT-based model running, we decided to go with the RoBERTa and DistiliBERT variations of BERT.
* RoBERTa was appealing because it ‚Äúremoves BERT‚Äôs next-sentence pretraining objective,‚Äù which is helpful because tweets are more like single sentences than long paragraphs. This model was run in Google Colab because difficulties arose with setting up a container in Temple‚Äôs HPC GPU cluster.
* DistilBERT is a simpler form of BERT and ‚Äúhas 40% less parameters than bert-base-uncased, runs 60% faster while preserving over 95% of BERT‚Äôs performances as measured on the GLUE language understanding benchmark‚Äù (see source). We were curious how big the tradeoff between training time and performance would be with this model. In the initial stages of the project, the DistilBERT model was taking a long time to run even in Temple‚Äôs HPC GPU cluster, so in order to speed up feature extraction,  the algorithm was ran once with the feature weights saved to a text file so that more time could be spent examining hyperparameter optimization. Ultimately though, the tradeoff between performance and training time for DistiliBERT wasn‚Äôt too heavily explored as the RoBERTa model, which used Google Colab, was selected for final use instead of DistilliBERT so the challenges with running it on Temple‚Äôs GPU resources were able to be avoided.

Brendan Magdamo created the RoBERTa model and Brendan Manning created a DistilBERT model. Through a lengthy process of adjustments, the RoBERTa model eventually achieved an F1 score of 0.835 while the DistilBERT one achieved an F1 score of approximately 0.78. Accordingly, the RoBERTa model was chosen for use in the final phase of the project and will be used for the creation of the final dashboard illustrating the model‚Äôs performance.

## Hyperparameter Tuning
We used Optuna and Weights and Biases hyperparameter tuning to improve our model‚Äôs performance and outcome. 

When using wandb for hyperparameter tuning, we create our ClassificationArgs with wandb_project="DisasterTweets" so that we can track the progress of the wandb sweep online. Optuna hyperparameter tuning does not require this additional syntax. 

Using Optuna, we noticed that hyperparameters tended to converge to the optimal values very quickly. When tuning a 10-layer neural network, the optimal value was found after 305/10,000 iterations. Similarly when tuning a Logistic Regression model, it converged after 218 and 585 iterations in two separate trials. The maximum F1 score produced from these trials on Brendan Manning‚Äôs models (which were different from Brendan Magadmo‚Äôs and not the models ultimately chosen for Phase 3) were 0.761 and 0.773 respectively. What this did show us is that while the tested model types all performed similarly, Linear Regression was indeed a slightly better choice. See figures 1 and 2.

We also tried to optimize hyperparameters using quasi-cloud-based solution Weights and Biases (wandb). From this, we were able to monitor the progress of the tuning job in a convenient web portal with helpful graphs created in real-time. The setup process for this was incredibly time-consuming since wandb‚Äôs documentation for Simple Transformers was relatively weak. In particular, we noticed that for the ClassificationModel with multiple tuned parameters, there was not any directly comparable example code which made it challenging to figure out the syntax of certain configuration choices. This resulted in several hours of debugging after which, we were able to create a ‚Äúsweep config‚Äù that defined the ranges of the hyperparameters for which we wanted to tune as well as the model object we wanted to use them in and also the performance metric we wanted to maximize (roc_curve). See figure 3 on the final page for the sweep config we used. We also had trouble getting the sweep to run more than 20 iterations (we couldn‚Äôt find a parameter in wandb to change this and the trials seem to fail after a certain number of iterations). 

The final hyperparameter tuning job is being run as this document is written. We chose Optuna for the final tuning job because it is much simpler than Weights and Biases, meaning we could be sure we were doing it correctly. Optuna is also more industry-standard, so it will be helpful to talk about using it in future job interviews. 

## Figures
![alt text](https://github.com/bmagdamo1/DisasterTweets/blob/main/Docs/ModelReport/Optuna1.png?raw=true)   
Figure 1

![alt text](https://github.com/bmagdamo1/DisasterTweets/blob/main/Docs/ModelReport/Optuna2.png?raw=true)   
Figure 2

![alt text](https://github.com/bmagdamo1/DisasterTweets/blob/main/Docs/ModelReport/wandb.png?raw=true)   
Figure 3

![alt text](https://github.com/bmagdamo1/DisasterTweets/blob/main/Docs/ModelReport/Optuna3.png?raw=true)   
Figure 4

